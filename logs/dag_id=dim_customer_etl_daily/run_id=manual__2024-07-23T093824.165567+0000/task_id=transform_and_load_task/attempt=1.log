[2024-07-23T09:38:31.314+0000] {taskinstance.py:1956} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: dim_customer_etl_daily.transform_and_load_task manual__2024-07-23T09:38:24.165567+00:00 [queued]>
[2024-07-23T09:38:31.327+0000] {taskinstance.py:1956} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: dim_customer_etl_daily.transform_and_load_task manual__2024-07-23T09:38:24.165567+00:00 [queued]>
[2024-07-23T09:38:31.328+0000] {taskinstance.py:2170} INFO - Starting attempt 1 of 1
[2024-07-23T09:38:31.358+0000] {taskinstance.py:2191} INFO - Executing <Task(_PythonDecoratedOperator): transform_and_load_task> on 2024-07-23 09:38:24.165567+00:00
[2024-07-23T09:38:31.369+0000] {standard_task_runner.py:60} INFO - Started process 9201 to run task
[2024-07-23T09:38:31.376+0000] {standard_task_runner.py:87} INFO - Running: ['***', 'tasks', 'run', 'dim_customer_etl_daily', 'transform_and_load_task', 'manual__2024-07-23T09:38:24.165567+00:00', '--job-id', '307', '--raw', '--subdir', 'DAGS_FOLDER/dim_customer.py', '--cfg-path', '/tmp/tmp_bc16prw']
[2024-07-23T09:38:31.379+0000] {standard_task_runner.py:88} INFO - Job 307: Subtask transform_and_load_task
[2024-07-23T09:38:31.467+0000] {task_command.py:423} INFO - Running <TaskInstance: dim_customer_etl_daily.transform_and_load_task manual__2024-07-23T09:38:24.165567+00:00 [running]> on host 087c584822ad
[2024-07-23T09:38:31.575+0000] {taskinstance.py:2480} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='dim_customer_etl_daily' AIRFLOW_CTX_TASK_ID='transform_and_load_task' AIRFLOW_CTX_EXECUTION_DATE='2024-07-23T09:38:24.165567+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-07-23T09:38:24.165567+00:00'
[2024-07-23T09:38:31.578+0000] {logging_mixin.py:188} INFO - Start data transformation and load stage
[2024-07-23T09:38:32.395+0000] {pipeline_options.py:923} WARNING - Bucket specified in temp_location has soft-delete policy enabled. To avoid being billed for unnecessary storage costs, turn off the soft delete feature on buckets that your Dataflow jobs use for temporary and staging storage. For more information, see https://cloud.google.com/storage/docs/use-soft-delete#remove-soft-delete-policy.
[2024-07-23T09:38:32.711+0000] {pipeline_options.py:923} WARNING - Bucket specified in staging_location has soft-delete policy enabled. To avoid being billed for unnecessary storage costs, turn off the soft delete feature on buckets that your Dataflow jobs use for temporary and staging storage. For more information, see https://cloud.google.com/storage/docs/use-soft-delete#remove-soft-delete-policy.
[2024-07-23T09:38:34.542+0000] {pipeline_options.py:923} WARNING - Bucket specified in temp_location has soft-delete policy enabled. To avoid being billed for unnecessary storage costs, turn off the soft delete feature on buckets that your Dataflow jobs use for temporary and staging storage. For more information, see https://cloud.google.com/storage/docs/use-soft-delete#remove-soft-delete-policy.
[2024-07-23T09:38:34.775+0000] {pipeline_options.py:923} WARNING - Bucket specified in staging_location has soft-delete policy enabled. To avoid being billed for unnecessary storage costs, turn off the soft delete feature on buckets that your Dataflow jobs use for temporary and staging storage. For more information, see https://cloud.google.com/storage/docs/use-soft-delete#remove-soft-delete-policy.
[2024-07-23T09:38:34.982+0000] {stager.py:800} INFO - Executing command: ['/usr/local/bin/python', '-m', 'build', '--no-isolation', '--sdist', '--outdir', '/tmp/tmpdocqh7cz', '/opt/***/plugins']
[2024-07-23T09:38:35.037+0000] {stager.py:810} INFO - Executing command: ['/usr/local/bin/python', 'setup.py', 'sdist', '--dist-dir', '/tmp/tmpdocqh7cz']
[2024-07-23T09:38:36.843+0000] {dataflow_runner.py:397} INFO - Pipeline has additional dependencies to be installed in SDK worker container, consider using the SDK container image pre-building workflow to avoid repetitive installations. Learn more on https://cloud.google.com/dataflow/docs/guides/using-custom-containers#prebuild
[2024-07-23T09:38:36.846+0000] {environments.py:314} INFO - Using provided Python SDK container image: gcr.io/cloud-dataflow/v1beta3/beam_python3.8_sdk:2.57.0
[2024-07-23T09:38:36.847+0000] {environments.py:321} INFO - Python SDK container image set to "gcr.io/cloud-dataflow/v1beta3/beam_python3.8_sdk:2.57.0" for Docker environment
[2024-07-23T09:38:37.154+0000] {apiclient.py:663} INFO - Starting GCS upload to gs://ingestion_layer/staging/dim-customer-bigquery-etl.1721727517.143546/workflow.tar.gz...
[2024-07-23T09:38:38.170+0000] {apiclient.py:673} INFO - Completed GCS upload to gs://ingestion_layer/staging/dim-customer-bigquery-etl.1721727517.143546/workflow.tar.gz in 1 seconds.
[2024-07-23T09:38:38.171+0000] {apiclient.py:663} INFO - Starting GCS upload to gs://ingestion_layer/staging/dim-customer-bigquery-etl.1721727517.143546/submission_environment_dependencies.txt...
[2024-07-23T09:38:39.099+0000] {apiclient.py:673} INFO - Completed GCS upload to gs://ingestion_layer/staging/dim-customer-bigquery-etl.1721727517.143546/submission_environment_dependencies.txt in 0 seconds.
[2024-07-23T09:38:39.100+0000] {apiclient.py:663} INFO - Starting GCS upload to gs://ingestion_layer/staging/dim-customer-bigquery-etl.1721727517.143546/pipeline.pb...
[2024-07-23T09:38:40.213+0000] {apiclient.py:673} INFO - Completed GCS upload to gs://ingestion_layer/staging/dim-customer-bigquery-etl.1721727517.143546/pipeline.pb in 1 seconds.
[2024-07-23T09:38:40.247+0000] {pipeline_options.py:339} WARNING - Unknown pipeline options received: celery,worker. Ignore if flags are used for internal purposes.
[2024-07-23T09:38:40.272+0000] {pipeline_options.py:339} WARNING - Unknown pipeline options received: celery,worker. Ignore if flags are used for internal purposes.
[2024-07-23T09:38:41.722+0000] {apiclient.py:844} INFO - Create job: <Job
 clientRequestId: '20240723093837144674-9410'
 createTime: '2024-07-23T09:38:44.152046Z'
 currentStateTime: '1970-01-01T00:00:00Z'
 id: '2024-07-23_02_38_43-17252619900845785093'
 location: 'asia-southeast2'
 name: 'dim-customer-bigquery-etl'
 projectId: 'liquid-kite-423215-s2'
 stageStates: []
 startTime: '2024-07-23T09:38:44.152046Z'
 steps: []
 tempFiles: []
 type: TypeValueValuesEnum(JOB_TYPE_BATCH, 1)>
[2024-07-23T09:38:41.724+0000] {apiclient.py:846} INFO - Created job with id: [2024-07-23_02_38_43-17252619900845785093]
[2024-07-23T09:38:41.725+0000] {apiclient.py:847} INFO - Submitted job: 2024-07-23_02_38_43-17252619900845785093
[2024-07-23T09:38:41.725+0000] {apiclient.py:848} INFO - To access the Dataflow monitoring console, please navigate to https://console.cloud.google.com/dataflow/jobs/asia-southeast2/2024-07-23_02_38_43-17252619900845785093?project=liquid-kite-423215-s2
[2024-07-23T09:38:42.177+0000] {dataflow_runner.py:153} INFO - Job 2024-07-23_02_38_43-17252619900845785093 is in state JOB_STATE_PENDING
[2024-07-23T09:38:47.352+0000] {dataflow_runner.py:203} INFO - 2024-07-23T09:38:47.669Z: JOB_MESSAGE_BASIC: Worker configuration: n1-standard-1 in asia-southeast2-c.
[2024-07-23T09:38:52.753+0000] {dataflow_runner.py:203} INFO - 2024-07-23T09:38:50.254Z: JOB_MESSAGE_BASIC: Executing operation WriteToBigQuery/WriteToBigQuery/BigQueryBatchFileLoads/ImpulseEmptyPC/Impulse+WriteToBigQuery/WriteToBigQuery/BigQueryBatchFileLoads/ImpulseEmptyPC/FlatMap(<lambda at core.py:3788>)+WriteToBigQuery/WriteToBigQuery/BigQueryBatchFileLoads/ImpulseEmptyPC/Map(decode)
[2024-07-23T09:38:52.754+0000] {dataflow_runner.py:203} INFO - 2024-07-23T09:38:50.266Z: JOB_MESSAGE_BASIC: Executing operation Start/Impulse+Start/FlatMap(<lambda at core.py:3788>)+Start/Map(decode)
[2024-07-23T09:38:52.755+0000] {dataflow_runner.py:203} INFO - 2024-07-23T09:38:50.278Z: JOB_MESSAGE_BASIC: Executing operation WriteToBigQuery/WriteToBigQuery/BigQueryBatchFileLoads/ImpulseSingleElementPC/Impulse+WriteToBigQuery/WriteToBigQuery/BigQueryBatchFileLoads/ImpulseSingleElementPC/FlatMap(<lambda at core.py:3788>)+WriteToBigQuery/WriteToBigQuery/BigQueryBatchFileLoads/ImpulseSingleElementPC/Map(decode)+WriteToBigQuery/WriteToBigQuery/BigQueryBatchFileLoads/CopyJobNamePrefix+WriteToBigQuery/WriteToBigQuery/BigQueryBatchFileLoads/GenerateFilePrefix+WriteToBigQuery/WriteToBigQuery/BigQueryBatchFileLoads/LoadJobNamePrefix+WriteToBigQuery/WriteToBigQuery/BigQueryBatchFileLoads/SchemaModJobNamePrefix
[2024-07-23T09:38:52.755+0000] {dataflow_runner.py:203} INFO - 2024-07-23T09:38:50.290Z: JOB_MESSAGE_BASIC: Starting 1 workers in asia-southeast2...
[2024-07-23T09:38:52.756+0000] {dataflow_runner.py:203} INFO - 2024-07-23T09:38:50.291Z: JOB_MESSAGE_BASIC: Executing operation WriteLog/WriteLogGCS/Write/WriteImpl/DoOnce/Impulse+WriteLog/WriteLogGCS/Write/WriteImpl/DoOnce/FlatMap(<lambda at core.py:3788>)+WriteLog/WriteLogGCS/Write/WriteImpl/DoOnce/Map(decode)+WriteLog/WriteLogGCS/Write/WriteImpl/InitializeWrite
[2024-07-23T09:38:52.756+0000] {dataflow_runner.py:203} INFO - 2024-07-23T09:38:50.303Z: JOB_MESSAGE_BASIC: Executing operation ReadAvro/ReadAvro/Read/Impulse+ReadAvro/ReadAvro/Read/EmitSource+ref_AppliedPTransform_ReadAvro-ReadAvro-Read-SDFBoundedSourceReader-ParDo-SDFBoundedSourceDoFn-_13/PairWithRestriction+ref_AppliedPTransform_ReadAvro-ReadAvro-Read-SDFBoundedSourceReader-ParDo-SDFBoundedSourceDoFn-_13/SplitWithSizing
[2024-07-23T09:38:52.925+0000] {dataflow_runner.py:153} INFO - Job 2024-07-23_02_38_43-17252619900845785093 is in state JOB_STATE_RUNNING
[2024-07-23T09:42:39.384+0000] {dataflow_runner.py:203} INFO - 2024-07-23T09:42:38.082Z: JOB_MESSAGE_BASIC: All workers have finished the startup processes and began to receive work requests.
[2024-07-23T09:42:39.466+0000] {dataflow_runner.py:203} INFO - 2024-07-23T09:42:40.750Z: JOB_MESSAGE_BASIC: Finished operation Start/Impulse+Start/FlatMap(<lambda at core.py:3788>)+Start/Map(decode)
[2024-07-23T09:42:39.467+0000] {dataflow_runner.py:203} INFO - 2024-07-23T09:42:40.813Z: JOB_MESSAGE_BASIC: Finished operation WriteToBigQuery/WriteToBigQuery/BigQueryBatchFileLoads/ImpulseEmptyPC/Impulse+WriteToBigQuery/WriteToBigQuery/BigQueryBatchFileLoads/ImpulseEmptyPC/FlatMap(<lambda at core.py:3788>)+WriteToBigQuery/WriteToBigQuery/BigQueryBatchFileLoads/ImpulseEmptyPC/Map(decode)
[2024-07-23T09:42:39.468+0000] {dataflow_runner.py:203} INFO - 2024-07-23T09:42:40.923Z: JOB_MESSAGE_BASIC: Finished operation ReadAvro/ReadAvro/Read/Impulse+ReadAvro/ReadAvro/Read/EmitSource+ref_AppliedPTransform_ReadAvro-ReadAvro-Read-SDFBoundedSourceReader-ParDo-SDFBoundedSourceDoFn-_13/PairWithRestriction+ref_AppliedPTransform_ReadAvro-ReadAvro-Read-SDFBoundedSourceReader-ParDo-SDFBoundedSourceDoFn-_13/SplitWithSizing
[2024-07-23T09:42:39.468+0000] {dataflow_runner.py:203} INFO - 2024-07-23T09:42:40.980Z: JOB_MESSAGE_BASIC: Executing operation RemoveDuplicates/GroupByKey/Create
[2024-07-23T09:42:39.469+0000] {dataflow_runner.py:203} INFO - 2024-07-23T09:42:41.633Z: JOB_MESSAGE_BASIC: Finished operation RemoveDuplicates/GroupByKey/Create
[2024-07-23T09:42:39.469+0000] {dataflow_runner.py:203} INFO - 2024-07-23T09:42:41.690Z: JOB_MESSAGE_BASIC: Executing operation ref_AppliedPTransform_ReadAvro-ReadAvro-Read-SDFBoundedSourceReader-ParDo-SDFBoundedSourceDoFn-_13/ProcessElementAndRestrictionWithSizing+RemoveDuplicates/PairWithKey+RemoveDuplicates/GroupByKey/Write
[2024-07-23T09:42:44.788+0000] {dataflow_runner.py:203} INFO - 2024-07-23T09:42:41.938Z: JOB_MESSAGE_BASIC: Finished operation WriteToBigQuery/WriteToBigQuery/BigQueryBatchFileLoads/ImpulseSingleElementPC/Impulse+WriteToBigQuery/WriteToBigQuery/BigQueryBatchFileLoads/ImpulseSingleElementPC/FlatMap(<lambda at core.py:3788>)+WriteToBigQuery/WriteToBigQuery/BigQueryBatchFileLoads/ImpulseSingleElementPC/Map(decode)+WriteToBigQuery/WriteToBigQuery/BigQueryBatchFileLoads/CopyJobNamePrefix+WriteToBigQuery/WriteToBigQuery/BigQueryBatchFileLoads/GenerateFilePrefix+WriteToBigQuery/WriteToBigQuery/BigQueryBatchFileLoads/LoadJobNamePrefix+WriteToBigQuery/WriteToBigQuery/BigQueryBatchFileLoads/SchemaModJobNamePrefix
[2024-07-23T09:42:44.789+0000] {dataflow_runner.py:203} INFO - 2024-07-23T09:42:42.017Z: JOB_MESSAGE_BASIC: Executing operation WriteToBigQuery/WriteToBigQuery/BigQueryBatchFileLoads/ParDo(TriggerCopyJobs)/ParDo(TriggerCopyJobs)/View-python_side_input0
[2024-07-23T09:42:44.790+0000] {dataflow_runner.py:203} INFO - 2024-07-23T09:42:42.029Z: JOB_MESSAGE_BASIC: Executing operation WriteToBigQuery/WriteToBigQuery/BigQueryBatchFileLoads/WriteGroupedRecordsToFile/View-python_side_input0
[2024-07-23T09:42:44.791+0000] {dataflow_runner.py:203} INFO - 2024-07-23T09:42:42.040Z: JOB_MESSAGE_BASIC: Executing operation WriteToBigQuery/WriteToBigQuery/BigQueryBatchFileLoads/ParDo(WriteRecordsToFile)/ParDo(WriteRecordsToFile)/View-python_side_input0
[2024-07-23T09:42:44.791+0000] {dataflow_runner.py:203} INFO - 2024-07-23T09:42:42.053Z: JOB_MESSAGE_BASIC: Executing operation WriteToBigQuery/WriteToBigQuery/BigQueryBatchFileLoads/TriggerLoadJobsWithTempTables/ParDo(TriggerLoadJobs)/View-python_side_input0
[2024-07-23T09:42:44.792+0000] {dataflow_runner.py:203} INFO - 2024-07-23T09:42:42.069Z: JOB_MESSAGE_BASIC: Executing operation WriteToBigQuery/WriteToBigQuery/BigQueryBatchFileLoads/TriggerLoadJobsWithoutTempTables/ParDo(TriggerLoadJobs)/View-python_side_input0
[2024-07-23T09:42:44.792+0000] {dataflow_runner.py:203} INFO - 2024-07-23T09:42:42.081Z: JOB_MESSAGE_BASIC: Executing operation WriteToBigQuery/WriteToBigQuery/BigQueryBatchFileLoads/ParDo(UpdateDestinationSchema)/View-python_side_input0
[2024-07-23T09:42:44.793+0000] {dataflow_runner.py:203} INFO - 2024-07-23T09:42:42.110Z: JOB_MESSAGE_BASIC: Finished operation WriteToBigQuery/WriteToBigQuery/BigQueryBatchFileLoads/ParDo(TriggerCopyJobs)/ParDo(TriggerCopyJobs)/View-python_side_input0
[2024-07-23T09:42:44.793+0000] {dataflow_runner.py:203} INFO - 2024-07-23T09:42:42.128Z: JOB_MESSAGE_BASIC: Finished operation WriteToBigQuery/WriteToBigQuery/BigQueryBatchFileLoads/WriteGroupedRecordsToFile/View-python_side_input0
[2024-07-23T09:42:44.794+0000] {dataflow_runner.py:203} INFO - 2024-07-23T09:42:42.145Z: JOB_MESSAGE_BASIC: Finished operation WriteToBigQuery/WriteToBigQuery/BigQueryBatchFileLoads/ParDo(WriteRecordsToFile)/ParDo(WriteRecordsToFile)/View-python_side_input0
[2024-07-23T09:42:44.794+0000] {dataflow_runner.py:203} INFO - 2024-07-23T09:42:42.145Z: JOB_MESSAGE_BASIC: Finished operation WriteToBigQuery/WriteToBigQuery/BigQueryBatchFileLoads/TriggerLoadJobsWithTempTables/ParDo(TriggerLoadJobs)/View-python_side_input0
[2024-07-23T09:42:44.795+0000] {dataflow_runner.py:203} INFO - 2024-07-23T09:42:42.167Z: JOB_MESSAGE_BASIC: Finished operation WriteToBigQuery/WriteToBigQuery/BigQueryBatchFileLoads/TriggerLoadJobsWithoutTempTables/ParDo(TriggerLoadJobs)/View-python_side_input0
[2024-07-23T09:42:44.795+0000] {dataflow_runner.py:203} INFO - 2024-07-23T09:42:42.180Z: JOB_MESSAGE_BASIC: Finished operation WriteToBigQuery/WriteToBigQuery/BigQueryBatchFileLoads/ParDo(UpdateDestinationSchema)/View-python_side_input0
[2024-07-23T09:42:44.795+0000] {dataflow_runner.py:203} INFO - 2024-07-23T09:42:42.540Z: JOB_MESSAGE_BASIC: Finished operation WriteLog/WriteLogGCS/Write/WriteImpl/DoOnce/Impulse+WriteLog/WriteLogGCS/Write/WriteImpl/DoOnce/FlatMap(<lambda at core.py:3788>)+WriteLog/WriteLogGCS/Write/WriteImpl/DoOnce/Map(decode)+WriteLog/WriteLogGCS/Write/WriteImpl/InitializeWrite
[2024-07-23T09:42:44.796+0000] {dataflow_runner.py:203} INFO - 2024-07-23T09:42:42.610Z: JOB_MESSAGE_BASIC: Executing operation WriteLog/WriteLogGCS/Write/WriteImpl/WriteBundles/View-python_side_input0
[2024-07-23T09:42:44.796+0000] {dataflow_runner.py:203} INFO - 2024-07-23T09:42:42.622Z: JOB_MESSAGE_BASIC: Executing operation WriteLog/WriteLogGCS/Write/WriteImpl/FinalizeWrite/View-python_side_input0
[2024-07-23T09:42:44.797+0000] {dataflow_runner.py:203} INFO - 2024-07-23T09:42:42.636Z: JOB_MESSAGE_BASIC: Executing operation WriteLog/WriteLogGCS/Write/WriteImpl/PreFinalize/View-python_side_input0
[2024-07-23T09:42:44.797+0000] {dataflow_runner.py:203} INFO - 2024-07-23T09:42:42.713Z: JOB_MESSAGE_BASIC: Finished operation WriteLog/WriteLogGCS/Write/WriteImpl/WriteBundles/View-python_side_input0
[2024-07-23T09:42:44.798+0000] {dataflow_runner.py:203} INFO - 2024-07-23T09:42:42.719Z: JOB_MESSAGE_BASIC: Finished operation WriteLog/WriteLogGCS/Write/WriteImpl/FinalizeWrite/View-python_side_input0
[2024-07-23T09:42:44.799+0000] {dataflow_runner.py:203} INFO - 2024-07-23T09:42:42.742Z: JOB_MESSAGE_BASIC: Finished operation WriteLog/WriteLogGCS/Write/WriteImpl/PreFinalize/View-python_side_input0
[2024-07-23T09:42:44.799+0000] {dataflow_runner.py:203} INFO - 2024-07-23T09:42:43.496Z: JOB_MESSAGE_BASIC: Finished operation ref_AppliedPTransform_ReadAvro-ReadAvro-Read-SDFBoundedSourceReader-ParDo-SDFBoundedSourceDoFn-_13/ProcessElementAndRestrictionWithSizing+RemoveDuplicates/PairWithKey+RemoveDuplicates/GroupByKey/Write
[2024-07-23T09:42:44.799+0000] {dataflow_runner.py:203} INFO - 2024-07-23T09:42:43.525Z: JOB_MESSAGE_BASIC: Executing operation RemoveDuplicates/GroupByKey/Close
[2024-07-23T09:42:44.800+0000] {dataflow_runner.py:203} INFO - 2024-07-23T09:42:43.563Z: JOB_MESSAGE_BASIC: Finished operation RemoveDuplicates/GroupByKey/Close
[2024-07-23T09:42:44.800+0000] {dataflow_runner.py:203} INFO - 2024-07-23T09:42:43.593Z: JOB_MESSAGE_BASIC: Executing operation WriteToBigQuery/WriteToBigQuery/BigQueryBatchFileLoads/GroupShardedRows/Create
[2024-07-23T09:42:44.800+0000] {dataflow_runner.py:203} INFO - 2024-07-23T09:42:43.606Z: JOB_MESSAGE_BASIC: Executing operation FindMaxDateString/CombinePerKey/GroupByKey/Create
[2024-07-23T09:42:44.801+0000] {dataflow_runner.py:203} INFO - 2024-07-23T09:42:43.686Z: JOB_MESSAGE_BASIC: Finished operation WriteToBigQuery/WriteToBigQuery/BigQueryBatchFileLoads/GroupShardedRows/Create
[2024-07-23T09:42:44.801+0000] {dataflow_runner.py:203} INFO - 2024-07-23T09:42:43.707Z: JOB_MESSAGE_BASIC: Finished operation FindMaxDateString/CombinePerKey/GroupByKey/Create
[2024-07-23T09:42:44.801+0000] {dataflow_runner.py:203} INFO - 2024-07-23T09:42:43.753Z: JOB_MESSAGE_BASIC: Executing operation WriteToBigQuery/WriteToBigQuery/BigQueryBatchFileLoads/GroupFilesByTableDestinations/Create
[2024-07-23T09:42:44.802+0000] {dataflow_runner.py:203} INFO - 2024-07-23T09:42:43.842Z: JOB_MESSAGE_BASIC: Finished operation WriteToBigQuery/WriteToBigQuery/BigQueryBatchFileLoads/GroupFilesByTableDestinations/Create
[2024-07-23T09:42:44.802+0000] {dataflow_runner.py:203} INFO - 2024-07-23T09:42:43.899Z: JOB_MESSAGE_BASIC: Executing operation RemoveDuplicates/GroupByKey/Read+RemoveDuplicates/RemoveDuplicates+ExtractDateString+WriteToBigQuery/WriteToBigQuery/BigQueryBatchFileLoads/RewindowIntoGlobal+FindMaxDateString/KeyWithVoid+FindMaxDateString/CombinePerKey/GroupByKey+FindMaxDateString/CombinePerKey/Combine/Partial+FindMaxDateString/CombinePerKey/GroupByKey/Write+WriteToBigQuery/WriteToBigQuery/BigQueryBatchFileLoads/AppendDestination+WriteToBigQuery/WriteToBigQuery/BigQueryBatchFileLoads/ParDo(WriteRecordsToFile)/ParDo(WriteRecordsToFile)+WriteToBigQuery/WriteToBigQuery/BigQueryBatchFileLoads/IdentityWorkaround+WriteToBigQuery/WriteToBigQuery/BigQueryBatchFileLoads/GroupFilesByTableDestinations/Write+WriteToBigQuery/WriteToBigQuery/BigQueryBatchFileLoads/ParDo(_ShardDestinations)+WriteToBigQuery/WriteToBigQuery/BigQueryBatchFileLoads/GroupShardedRows/Write
[2024-07-23T09:42:44.802+0000] {dataflow_runner.py:203} INFO - 2024-07-23T09:42:45.213Z: JOB_MESSAGE_BASIC: Finished operation RemoveDuplicates/GroupByKey/Read+RemoveDuplicates/RemoveDuplicates+ExtractDateString+WriteToBigQuery/WriteToBigQuery/BigQueryBatchFileLoads/RewindowIntoGlobal+FindMaxDateString/KeyWithVoid+FindMaxDateString/CombinePerKey/GroupByKey+FindMaxDateString/CombinePerKey/Combine/Partial+FindMaxDateString/CombinePerKey/GroupByKey/Write+WriteToBigQuery/WriteToBigQuery/BigQueryBatchFileLoads/AppendDestination+WriteToBigQuery/WriteToBigQuery/BigQueryBatchFileLoads/ParDo(WriteRecordsToFile)/ParDo(WriteRecordsToFile)+WriteToBigQuery/WriteToBigQuery/BigQueryBatchFileLoads/IdentityWorkaround+WriteToBigQuery/WriteToBigQuery/BigQueryBatchFileLoads/GroupFilesByTableDestinations/Write+WriteToBigQuery/WriteToBigQuery/BigQueryBatchFileLoads/ParDo(_ShardDestinations)+WriteToBigQuery/WriteToBigQuery/BigQueryBatchFileLoads/GroupShardedRows/Write
[2024-07-23T09:42:44.803+0000] {dataflow_runner.py:203} INFO - 2024-07-23T09:42:45.246Z: JOB_MESSAGE_BASIC: Executing operation WriteToBigQuery/WriteToBigQuery/BigQueryBatchFileLoads/GroupShardedRows/Close
[2024-07-23T09:42:44.803+0000] {dataflow_runner.py:203} INFO - 2024-07-23T09:42:45.258Z: JOB_MESSAGE_BASIC: Executing operation FindMaxDateString/CombinePerKey/GroupByKey/Close
[2024-07-23T09:42:44.803+0000] {dataflow_runner.py:203} INFO - 2024-07-23T09:42:45.278Z: JOB_MESSAGE_BASIC: Finished operation WriteToBigQuery/WriteToBigQuery/BigQueryBatchFileLoads/GroupShardedRows/Close
[2024-07-23T09:42:44.804+0000] {dataflow_runner.py:203} INFO - 2024-07-23T09:42:45.307Z: JOB_MESSAGE_BASIC: Executing operation WriteToBigQuery/WriteToBigQuery/BigQueryBatchFileLoads/GroupShardedRows/Read+WriteToBigQuery/WriteToBigQuery/BigQueryBatchFileLoads/DropShardNumber+WriteToBigQuery/WriteToBigQuery/BigQueryBatchFileLoads/WriteGroupedRecordsToFile+WriteToBigQuery/WriteToBigQuery/BigQueryBatchFileLoads/DestinationFilesUnion/InputIdentity+WriteToBigQuery/WriteToBigQuery/BigQueryBatchFileLoads/IdentityWorkaround+WriteToBigQuery/WriteToBigQuery/BigQueryBatchFileLoads/GroupFilesByTableDestinations/Write
[2024-07-23T09:42:44.804+0000] {dataflow_runner.py:203} INFO - 2024-07-23T09:42:45.582Z: JOB_MESSAGE_BASIC: Finished operation FindMaxDateString/CombinePerKey/GroupByKey/Close
[2024-07-23T09:42:44.805+0000] {dataflow_runner.py:203} INFO - 2024-07-23T09:42:45.611Z: JOB_MESSAGE_BASIC: Executing operation FindMaxDateString/CombinePerKey/GroupByKey/Read+FindMaxDateString/CombinePerKey/Combine+FindMaxDateString/CombinePerKey/Combine/Extract+FindMaxDateString/UnKey
[2024-07-23T09:42:44.806+0000] {dataflow_runner.py:203} INFO - 2024-07-23T09:42:45.627Z: JOB_MESSAGE_BASIC: Finished operation WriteToBigQuery/WriteToBigQuery/BigQueryBatchFileLoads/GroupShardedRows/Read+WriteToBigQuery/WriteToBigQuery/BigQueryBatchFileLoads/DropShardNumber+WriteToBigQuery/WriteToBigQuery/BigQueryBatchFileLoads/WriteGroupedRecordsToFile+WriteToBigQuery/WriteToBigQuery/BigQueryBatchFileLoads/DestinationFilesUnion/InputIdentity+WriteToBigQuery/WriteToBigQuery/BigQueryBatchFileLoads/IdentityWorkaround+WriteToBigQuery/WriteToBigQuery/BigQueryBatchFileLoads/GroupFilesByTableDestinations/Write
[2024-07-23T09:42:44.806+0000] {dataflow_runner.py:203} INFO - 2024-07-23T09:42:45.655Z: JOB_MESSAGE_BASIC: Executing operation WriteToBigQuery/WriteToBigQuery/BigQueryBatchFileLoads/GroupFilesByTableDestinations/Close
[2024-07-23T09:42:44.807+0000] {dataflow_runner.py:203} INFO - 2024-07-23T09:42:45.687Z: JOB_MESSAGE_BASIC: Finished operation WriteToBigQuery/WriteToBigQuery/BigQueryBatchFileLoads/GroupFilesByTableDestinations/Close
[2024-07-23T09:42:44.808+0000] {dataflow_runner.py:203} INFO - 2024-07-23T09:42:45.718Z: JOB_MESSAGE_BASIC: Executing operation WriteToBigQuery/WriteToBigQuery/BigQueryBatchFileLoads/GroupFilesByTableDestinations/Read+WriteToBigQuery/WriteToBigQuery/BigQueryBatchFileLoads/ParDo(PartitionFiles)/ParDo(PartitionFiles)+WriteToBigQuery/WriteToBigQuery/BigQueryBatchFileLoads/TriggerLoadJobsWithTempTables/ParDo(TriggerLoadJobs)+WriteToBigQuery/WriteToBigQuery/BigQueryBatchFileLoads/Map(<lambda at bigquery_file_loads.py:1145>)+WriteToBigQuery/WriteToBigQuery/BigQueryBatchFileLoads/ParDo(UpdateDestinationSchema)+WriteToBigQuery/WriteToBigQuery/BigQueryBatchFileLoads/TriggerLoadJobsWithoutTempTables/ParDo(TriggerLoadJobs)
[2024-07-23T09:42:50.176+0000] {dataflow_runner.py:203} INFO - 2024-07-23T09:42:48.219Z: JOB_MESSAGE_BASIC: Finished operation FindMaxDateString/CombinePerKey/GroupByKey/Read+FindMaxDateString/CombinePerKey/Combine+FindMaxDateString/CombinePerKey/Combine/Extract+FindMaxDateString/UnKey
[2024-07-23T09:42:50.249+0000] {dataflow_runner.py:203} INFO - 2024-07-23T09:42:48.277Z: JOB_MESSAGE_BASIC: Executing operation FindMaxDateString/InjectDefault/View-python_side_input0
[2024-07-23T09:42:50.302+0000] {dataflow_runner.py:203} INFO - 2024-07-23T09:42:48.382Z: JOB_MESSAGE_BASIC: Finished operation FindMaxDateString/InjectDefault/View-python_side_input0
[2024-07-23T09:42:50.342+0000] {dataflow_runner.py:203} INFO - 2024-07-23T09:42:48.439Z: JOB_MESSAGE_BASIC: Executing operation WriteLog/WriteLogGCS/Write/WriteImpl/GroupByKey/Create
[2024-07-23T09:42:50.354+0000] {dataflow_runner.py:203} INFO - 2024-07-23T09:42:48.553Z: JOB_MESSAGE_BASIC: Finished operation WriteLog/WriteLogGCS/Write/WriteImpl/GroupByKey/Create
[2024-07-23T09:42:50.368+0000] {dataflow_runner.py:203} INFO - 2024-07-23T09:42:48.614Z: JOB_MESSAGE_BASIC: Executing operation FindMaxDateString/DoOnce/Impulse+FindMaxDateString/DoOnce/FlatMap(<lambda at core.py:3788>)+FindMaxDateString/DoOnce/Map(decode)+FindMaxDateString/InjectDefault+WriteLog/WriteLogGCS/Write/WriteImpl/WindowInto(WindowIntoFn)+WriteLog/WriteLogGCS/Write/WriteImpl/WriteBundles+WriteLog/WriteLogGCS/Write/WriteImpl/Pair+WriteLog/WriteLogGCS/Write/WriteImpl/GroupByKey/Write
[2024-07-23T09:43:01.198+0000] {dataflow_runner.py:203} INFO - 2024-07-23T09:43:00.883Z: JOB_MESSAGE_BASIC: Finished operation FindMaxDateString/DoOnce/Impulse+FindMaxDateString/DoOnce/FlatMap(<lambda at core.py:3788>)+FindMaxDateString/DoOnce/Map(decode)+FindMaxDateString/InjectDefault+WriteLog/WriteLogGCS/Write/WriteImpl/WindowInto(WindowIntoFn)+WriteLog/WriteLogGCS/Write/WriteImpl/WriteBundles+WriteLog/WriteLogGCS/Write/WriteImpl/Pair+WriteLog/WriteLogGCS/Write/WriteImpl/GroupByKey/Write
[2024-07-23T09:43:01.198+0000] {dataflow_runner.py:203} INFO - 2024-07-23T09:43:00.913Z: JOB_MESSAGE_BASIC: Executing operation WriteLog/WriteLogGCS/Write/WriteImpl/GroupByKey/Close
[2024-07-23T09:43:01.199+0000] {dataflow_runner.py:203} INFO - 2024-07-23T09:43:01.137Z: JOB_MESSAGE_BASIC: Finished operation WriteLog/WriteLogGCS/Write/WriteImpl/GroupByKey/Close
[2024-07-23T09:43:01.199+0000] {dataflow_runner.py:203} INFO - 2024-07-23T09:43:01.167Z: JOB_MESSAGE_BASIC: Executing operation WriteLog/WriteLogGCS/Write/WriteImpl/GroupByKey/Read+WriteLog/WriteLogGCS/Write/WriteImpl/Extract
[2024-07-23T09:43:01.200+0000] {dataflow_runner.py:203} INFO - 2024-07-23T09:43:01.273Z: JOB_MESSAGE_BASIC: Finished operation WriteToBigQuery/WriteToBigQuery/BigQueryBatchFileLoads/GroupFilesByTableDestinations/Read+WriteToBigQuery/WriteToBigQuery/BigQueryBatchFileLoads/ParDo(PartitionFiles)/ParDo(PartitionFiles)+WriteToBigQuery/WriteToBigQuery/BigQueryBatchFileLoads/TriggerLoadJobsWithTempTables/ParDo(TriggerLoadJobs)+WriteToBigQuery/WriteToBigQuery/BigQueryBatchFileLoads/Map(<lambda at bigquery_file_loads.py:1145>)+WriteToBigQuery/WriteToBigQuery/BigQueryBatchFileLoads/ParDo(UpdateDestinationSchema)+WriteToBigQuery/WriteToBigQuery/BigQueryBatchFileLoads/TriggerLoadJobsWithoutTempTables/ParDo(TriggerLoadJobs)
[2024-07-23T09:43:01.200+0000] {dataflow_runner.py:203} INFO - 2024-07-23T09:43:01.373Z: JOB_MESSAGE_BASIC: Executing operation WriteToBigQuery/WriteToBigQuery/BigQueryBatchFileLoads/ParDo(TriggerCopyJobs)/ParDo(TriggerCopyJobs)/View-python_side_input1
[2024-07-23T09:43:01.201+0000] {dataflow_runner.py:203} INFO - 2024-07-23T09:43:01.388Z: JOB_MESSAGE_BASIC: Executing operation WriteToBigQuery/WriteToBigQuery/BigQueryBatchFileLoads/Flatten
[2024-07-23T09:43:01.201+0000] {dataflow_runner.py:203} INFO - 2024-07-23T09:43:01.464Z: JOB_MESSAGE_BASIC: Finished operation WriteToBigQuery/WriteToBigQuery/BigQueryBatchFileLoads/ParDo(TriggerCopyJobs)/ParDo(TriggerCopyJobs)/View-python_side_input1
[2024-07-23T09:43:01.202+0000] {dataflow_runner.py:203} INFO - 2024-07-23T09:43:01.530Z: JOB_MESSAGE_BASIC: Executing operation WriteToBigQuery/WriteToBigQuery/BigQueryBatchFileLoads/ParDo(TriggerCopyJobs)/ParDo(TriggerCopyJobs)
[2024-07-23T09:43:01.202+0000] {dataflow_runner.py:203} INFO - 2024-07-23T09:43:01.571Z: JOB_MESSAGE_BASIC: Finished operation WriteToBigQuery/WriteToBigQuery/BigQueryBatchFileLoads/Flatten
[2024-07-23T09:43:06.531+0000] {dataflow_runner.py:203} INFO - 2024-07-23T09:43:03.820Z: JOB_MESSAGE_BASIC: Finished operation WriteLog/WriteLogGCS/Write/WriteImpl/GroupByKey/Read+WriteLog/WriteLogGCS/Write/WriteImpl/Extract
[2024-07-23T09:43:06.532+0000] {dataflow_runner.py:203} INFO - 2024-07-23T09:43:03.887Z: JOB_MESSAGE_BASIC: Executing operation WriteLog/WriteLogGCS/Write/WriteImpl/FinalizeWrite/View-python_side_input1
[2024-07-23T09:43:06.533+0000] {dataflow_runner.py:203} INFO - 2024-07-23T09:43:03.900Z: JOB_MESSAGE_BASIC: Executing operation WriteLog/WriteLogGCS/Write/WriteImpl/PreFinalize/View-python_side_input1
[2024-07-23T09:43:06.533+0000] {dataflow_runner.py:203} INFO - 2024-07-23T09:43:03.995Z: JOB_MESSAGE_BASIC: Finished operation WriteLog/WriteLogGCS/Write/WriteImpl/FinalizeWrite/View-python_side_input1
[2024-07-23T09:43:06.544+0000] {dataflow_runner.py:203} INFO - 2024-07-23T09:43:04.003Z: JOB_MESSAGE_BASIC: Finished operation WriteLog/WriteLogGCS/Write/WriteImpl/PreFinalize/View-python_side_input1
[2024-07-23T09:43:06.545+0000] {dataflow_runner.py:203} INFO - 2024-07-23T09:43:04.067Z: JOB_MESSAGE_BASIC: Executing operation WriteLog/WriteLogGCS/Write/WriteImpl/PreFinalize
[2024-07-23T09:43:06.546+0000] {dataflow_runner.py:203} INFO - 2024-07-23T09:43:04.722Z: JOB_MESSAGE_BASIC: Finished operation WriteToBigQuery/WriteToBigQuery/BigQueryBatchFileLoads/ParDo(TriggerCopyJobs)/ParDo(TriggerCopyJobs)
[2024-07-23T09:43:06.547+0000] {dataflow_runner.py:203} INFO - 2024-07-23T09:43:04.791Z: JOB_MESSAGE_BASIC: Executing operation WriteToBigQuery/WriteToBigQuery/BigQueryBatchFileLoads/RemoveTempTables/AddUselessValue/View-python_side_input0
[2024-07-23T09:43:06.548+0000] {dataflow_runner.py:203} INFO - 2024-07-23T09:43:04.891Z: JOB_MESSAGE_BASIC: Finished operation WriteToBigQuery/WriteToBigQuery/BigQueryBatchFileLoads/RemoveTempTables/AddUselessValue/View-python_side_input0
[2024-07-23T09:43:06.549+0000] {dataflow_runner.py:203} INFO - 2024-07-23T09:43:04.949Z: JOB_MESSAGE_BASIC: Executing operation WriteToBigQuery/WriteToBigQuery/BigQueryBatchFileLoads/RemoveTempTables/DeduplicateTables/Create
[2024-07-23T09:43:06.550+0000] {dataflow_runner.py:203} INFO - 2024-07-23T09:43:05.152Z: JOB_MESSAGE_BASIC: Finished operation WriteToBigQuery/WriteToBigQuery/BigQueryBatchFileLoads/RemoveTempTables/DeduplicateTables/Create
[2024-07-23T09:43:06.550+0000] {dataflow_runner.py:203} INFO - 2024-07-23T09:43:05.209Z: JOB_MESSAGE_BASIC: Executing operation WriteToBigQuery/WriteToBigQuery/BigQueryBatchFileLoads/RemoveTempTables/AddUselessValue+WriteToBigQuery/WriteToBigQuery/BigQueryBatchFileLoads/RemoveTempTables/DeduplicateTables/Write
[2024-07-23T09:43:06.551+0000] {dataflow_runner.py:203} INFO - 2024-07-23T09:43:05.841Z: JOB_MESSAGE_BASIC: Finished operation WriteToBigQuery/WriteToBigQuery/BigQueryBatchFileLoads/RemoveTempTables/AddUselessValue+WriteToBigQuery/WriteToBigQuery/BigQueryBatchFileLoads/RemoveTempTables/DeduplicateTables/Write
[2024-07-23T09:43:06.558+0000] {dataflow_runner.py:203} INFO - 2024-07-23T09:43:05.870Z: JOB_MESSAGE_BASIC: Executing operation WriteToBigQuery/WriteToBigQuery/BigQueryBatchFileLoads/RemoveTempTables/DeduplicateTables/Close
[2024-07-23T09:43:06.560+0000] {dataflow_runner.py:203} INFO - 2024-07-23T09:43:05.903Z: JOB_MESSAGE_BASIC: Finished operation WriteToBigQuery/WriteToBigQuery/BigQueryBatchFileLoads/RemoveTempTables/DeduplicateTables/Close
[2024-07-23T09:43:06.561+0000] {dataflow_runner.py:203} INFO - 2024-07-23T09:43:05.933Z: JOB_MESSAGE_BASIC: Executing operation WriteToBigQuery/WriteToBigQuery/BigQueryBatchFileLoads/RemoveTempTables/DeduplicateTables/Read+WriteToBigQuery/WriteToBigQuery/BigQueryBatchFileLoads/RemoveTempTables/GetTableNames/Keys+WriteToBigQuery/WriteToBigQuery/BigQueryBatchFileLoads/RemoveTempTables/Delete
[2024-07-23T09:43:06.562+0000] {dataflow_runner.py:203} INFO - 2024-07-23T09:43:07.213Z: JOB_MESSAGE_BASIC: Finished operation WriteToBigQuery/WriteToBigQuery/BigQueryBatchFileLoads/RemoveTempTables/DeduplicateTables/Read+WriteToBigQuery/WriteToBigQuery/BigQueryBatchFileLoads/RemoveTempTables/GetTableNames/Keys+WriteToBigQuery/WriteToBigQuery/BigQueryBatchFileLoads/RemoveTempTables/Delete
[2024-07-23T09:43:06.562+0000] {dataflow_runner.py:203} INFO - 2024-07-23T09:43:08.272Z: JOB_MESSAGE_BASIC: Finished operation WriteLog/WriteLogGCS/Write/WriteImpl/PreFinalize
[2024-07-23T09:43:06.563+0000] {dataflow_runner.py:203} INFO - 2024-07-23T09:43:08.328Z: JOB_MESSAGE_BASIC: Executing operation WriteLog/WriteLogGCS/Write/WriteImpl/FinalizeWrite/View-python_side_input2
[2024-07-23T09:43:06.564+0000] {dataflow_runner.py:203} INFO - 2024-07-23T09:43:08.425Z: JOB_MESSAGE_BASIC: Finished operation WriteLog/WriteLogGCS/Write/WriteImpl/FinalizeWrite/View-python_side_input2
[2024-07-23T09:43:06.564+0000] {dataflow_runner.py:203} INFO - 2024-07-23T09:43:08.480Z: JOB_MESSAGE_BASIC: Executing operation WriteLog/WriteLogGCS/Write/WriteImpl/FinalizeWrite
[2024-07-23T09:43:12.010+0000] {dataflow_runner.py:203} INFO - 2024-07-23T09:43:11.682Z: JOB_MESSAGE_BASIC: Finished operation WriteLog/WriteLogGCS/Write/WriteImpl/FinalizeWrite
[2024-07-23T09:43:12.011+0000] {dataflow_runner.py:203} INFO - 2024-07-23T09:43:12.102Z: JOB_MESSAGE_BASIC: Stopping worker pool...
[2024-07-23T09:43:55.066+0000] {dataflow_runner.py:203} INFO - 2024-07-23T09:43:57.346Z: JOB_MESSAGE_BASIC: Worker pool stopped.
[2024-07-23T09:44:05.944+0000] {dataflow_runner.py:153} INFO - Job 2024-07-23_02_38_43-17252619900845785093 is in state JOB_STATE_DONE
[2024-07-23T09:44:07.058+0000] {logging_mixin.py:188} INFO - Transform and load stage successfully
[2024-07-23T09:44:07.088+0000] {python.py:201} INFO - Done. Returned value was: None
[2024-07-23T09:44:07.453+0000] {taskinstance.py:1138} INFO - Marking task as SUCCESS. dag_id=dim_customer_etl_daily, task_id=transform_and_load_task, execution_date=20240723T093824, start_date=20240723T093831, end_date=20240723T094407
[2024-07-23T09:44:07.662+0000] {local_task_job_runner.py:234} INFO - Task exited with return code 0
[2024-07-23T09:44:07.880+0000] {taskinstance.py:3280} INFO - 0 downstream tasks scheduled from follow-on schedule check
